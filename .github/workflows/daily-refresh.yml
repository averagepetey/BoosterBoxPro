# Daily TCGplayer refresh (Apify + Listings Scraper)
# Runs at 12:05am EST (05:05 UTC) to count previous day's complete sales.
# Schedule: GitHub runs this at 05:05 UTC daily; re-push this file if scheduled runs stop.
#
# Required secrets (Repo → Settings → Secrets and variables → Actions):
#   DATABASE_URL          - DB for all metrics (Apify + Scraper write here).
#   APIFY_API_TOKEN       - Phase 1: sales/volume (boxes_sold_per_day, unified_volume_usd, boxes_sold_30d_avg).
#   SERPAPI_API_KEY        - Phase 1b: eBay sold + active listings via SerpApi ($25/mo Starter plan).
#   BACKEND_URL           - Public API URL (e.g. https://your-api.run.app) so refresh can call invalidate-cache.
#   INVALIDATE_CACHE_SECRET - Secret for POST /hooks/invalidate-cache; required for leaderboard/box detail to show new data automatically.
#
# What updates what (both phases write to DB; app reads from DB):
# - Phase 1 (Apify): sales/volume — boxes_sold_per_day, unified_volume_usd, floor_price, boxes_sold_30d_avg.
# - Phase 1b (eBay SerpApi): eBay sold + active listings via SerpApi engine.
# - Phase 2 (Scraper): TCGplayer listings + price — floor_price_usd, active_listings_count, boxes_added_today.
# - Phase 3 (Rolling Metrics): Compute derived metrics (liquidity, days_to_20pct, EMAs) and upsert to DB.
# After all phases, the script calls cache invalidation so the API serves fresh data.

name: Daily Refresh (Apify + Scraper)

on:
  schedule:
    # 12:05am EST = 05:05 UTC (adjust if DST: 04:05 or 05:05)
    - cron: '5 5 * * *'
  workflow_dispatch: # allow manual run

jobs:
  daily-refresh:
    runs-on: ubuntu-latest
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Cache pip
        uses: actions/cache@v4
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('requirements.txt') }}

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Install Playwright browsers
        run: playwright install --with-deps chromium

      - name: Run daily refresh
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          APIFY_API_TOKEN: ${{ secrets.APIFY_API_TOKEN }}
          SERPAPI_API_KEY: ${{ secrets.SERPAPI_API_KEY }}
          BACKEND_URL: ${{ secrets.BACKEND_URL }}
          INVALIDATE_CACHE_SECRET: ${{ secrets.INVALIDATE_CACHE_SECRET }}
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            python scripts/daily_refresh.py --no-delay
          else
            python scripts/daily_refresh.py
          fi

